{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title B-SOiD GOOGLE COLAB \n",
    "# Created by Yttri Lab at Carnegie Mellon University.\n",
    "# Program developer: Alexander Hsu.\n",
    "# Program collaborator: Vishal Patel.\n",
    "# Date last modified: 030420\n",
    "# Contact: ahsu2@andrew.cmu.edu\n",
    "\n",
    "# Import necessary python packages\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "# import glob\n",
    "!pip install MulticoreTSNE\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn import mixture, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a few functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title BOXCAR_CENTER\n",
    "def boxcar_center(a, n):\n",
    "\n",
    "  a1 = pd.Series(a)\n",
    "  moving_avg = np.array(a1.rolling(window = n,min_periods=1).mean(center=True))\n",
    "  \n",
    "  return moving_avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title ADP_FILT\n",
    "def adp_filt(currDf=None,*args,**kwargs):\n",
    "\n",
    "    lIndex = []\n",
    "    xIndex = []\n",
    "    yIndex = []\n",
    "    currDf = np.array(currDf[1:])\n",
    "    for header in range(len(currDf[0])):\n",
    "        if currDf[0][header] == \"likelihood\":\n",
    "            lIndex.append(header)\n",
    "        elif currDf[0][header] == \"x\":\n",
    "            xIndex.append(header)\n",
    "        elif currDf[0][header] == \"y\":\n",
    "            yIndex.append(header)\n",
    "    print('Replacing data-driven low likelihood positions with the most recent highly probable position... \\n')\n",
    "    start_time = time.time()\n",
    "    currDf = np.array(currDf)\n",
    "    currDf1 = currDf[:,1:]\n",
    "    datax=currDf1[:,np.array(xIndex)-1]\n",
    "    datay=currDf1[:,np.array(yIndex)-1]\n",
    "    data_lh=currDf1[:,np.array(lIndex)-1]\n",
    "    currDf_filt = np.zeros((datax.shape[0]-1,(datax.shape[1])*2))\n",
    "    perc_rect = []\n",
    "    for i in range(data_lh.shape[1]):\n",
    "        perc_rect.append(0)\n",
    "    for x in range(data_lh.shape[1]):\n",
    "        if x <= 2:\n",
    "            a,b = np.histogram(data_lh[1:,x].astype(np.float))\n",
    "            rise_a = np.where(np.diff(a) >= 0)\n",
    "            if rise_a[0][0] > 1:\n",
    "                llh = (b[rise_a[0][0]]+b[rise_a[0][0]-1])/2\n",
    "            else:\n",
    "                llh = (b[rise_a[0][1]]+b[rise_a[0][1]-1])/2\n",
    "        else:\n",
    "            llh = 0.2\n",
    "        data_lh_float = data_lh[1:,x].astype(np.float)\n",
    "        perc_rect[x] = len(np.where(data_lh_float < llh)) / data_lh.shape[1]\n",
    "        currDf_filt[0,(2*x):(2*x + 2)] = np.hstack([datax[1,x],datay[1,x]])\n",
    "        # replacing with most recent highly probable positions\n",
    "        for i in range(1,data_lh.shape[0]-1):\n",
    "            if data_lh_float[i] < llh:\n",
    "                currDf_filt[i,(2*x):(2*x + 2)] = currDf_filt[i - 1,(2*x):(2*x + 2)]\n",
    "            else:\n",
    "                currDf_filt[i,(2*x):(2*x + 2)] = np.hstack([datax[i,x],datay[i,x]])\n",
    "    currDf_filt = np.array(currDf_filt[1:])\n",
    "    currDf_filt = currDf_filt.astype(np.float)\n",
    "    print(\"--- High-pass filter took %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return currDf_filt, perc_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Here I would like to save the data that I have, since it took a long time to process\n",
    "# %   DATA    6-body parts (x,y) matrix outlining the tetrapod animal over time videotaped from the bottom looking up. Rows represents time.\n",
    "# %           Columns 1 & 2 tracks snout; columns 3 to 6 tracks the two front paws; columns 7 to 10 tracks the two hind paws;\n",
    "# %           columns 11 & 12 tracks the base of the tail.\n",
    "# data[m][:,0:2]: \"snout\" --> left forepaw\n",
    "# data[m][:,2:4]: \"left forepaw\" --> right forepaw\n",
    "# data[m][:,4:6]: \"right forepaw\" --> nose\n",
    "# data[m][:,6:]: \"hindpaw\" --> sugar pellet\n",
    "\n",
    "fps = 100\n",
    "win_len = np.int(np.round(0.05/(1/fps))*2-1)\n",
    "print(win_len)\n",
    "time.time()\n",
    "\n",
    "# %%\n",
    "\n",
    "# @title B-SOiD_ASSIGN { vertical-output: true, display-mode: \"form\" }\n",
    "\n",
    "def bsoid_assign(clean_dlc_output, fps, comp, kclass, it, *args, **kwargs):\n",
    "    win_len = np.int(np.round(0.05 / (1 / fps)) * 2 - 1)\n",
    "    print('Obtaining features from dataset... \\n')\n",
    "    start_time = time.time()\n",
    "    feats = list()\n",
    "    for clean_trial in range(len(clean_dlc_output)):\n",
    "        ## Obtain features, 4 distance features and 3 time-varying speed/angle features\n",
    "        ## I WILL HAVE TO CHANGE THIS PART, LET'S SEE WHAT I CAN DO\n",
    "        \n",
    "        number_trials = len(clean_dlc_output[clean_trial])  # Number of trials imported for bsoid to run on\n",
    "        \n",
    "        # clean_dlc_output[clean_trial][:,0] = x-values snout\n",
    "        # clean_dlc_output[clean_trial][:,1] = y-values snout\n",
    "        # clean_dlc_output[clean_trial][:,2] = x-values fore paw 1\n",
    "        # clean_dlc_output[clean_trial][:,3] = y-values fore paw 1\n",
    "        # clean_dlc_output[clean_trial][:,4] = x-values fore paw 2\n",
    "        # clean_dlc_output[clean_trial][:,5] = y-values fore paw 2\n",
    "        # clean_dlc_output[clean_trial][:,6] = x-values hind paw 1\n",
    "        # clean_dlc_output[clean_trial][:,7] = y-values hind paw 1\n",
    "        # clean_dlc_output[clean_trial][:,8] = x-values hind paw 2\n",
    "        # clean_dlc_output[clean_trial][:,9] = y-values hind paw 2\n",
    "        # clean_dlc_output[clean_trial][:,10] = x-values base of tail\n",
    "        # clean_dlc_output[clean_trial][:,11] = y-values base of tail\n",
    "        \n",
    "        # clean_dlc_output[clean_trial][:,0] = x-values left paw (forepaw 1)\n",
    "        # clean_dlc_output[clean_trial][:,1] = y-values left paw (forepaw 1)\n",
    "        # clean_dlc_output[clean_trial][:,2] = x-values right paw (forepaw 2)\n",
    "        # clean_dlc_output[clean_trial][:,3] = y-values right paw (forepaw 2)\n",
    "        # clean_dlc_output[clean_trial][:,4] = x-values snout\n",
    "        # clean_dlc_output[clean_trial][:,5] = y-values snout\n",
    "        # clean_dlc_output[clean_trial][:,6] = x-values pellet\n",
    "        # clean_dlc_output[clean_trial][:,7] = y-values pellet\n",
    "        \n",
    "        forepaw_distance = clean_dlc_output[clean_trial][:, 0:2] - clean_dlc_output[clean_trial][:, 2:4]\n",
    "\n",
    "        center_between_forepaws = np.vstack(((clean_dlc_output[clean_trial][:, 0] + clean_dlc_output[clean_trial][:, 2]) / 2, (clean_dlc_output[clean_trial][:, 1] + clean_dlc_output[clean_trial][:, 3]) / 2)).T\n",
    "        length_center_between_forepaws = len(center_between_forepaws)\n",
    "        \n",
    "        point_center_between_forepaws = np.vstack(([center_between_forepaws[:, 0] - clean_dlc_output[clean_trial][:, 10], center_between_forepaws[:, 1] - clean_dlc_output[clean_trial][:, 11]])).T\n",
    "        \n",
    "        center_between_hindpaws = np.vstack((((clean_dlc_output[clean_trial][:, 6] + clean_dlc_output[clean_trial][:, 8]) / 2), ((clean_dlc_output[clean_trial][:, 7] + clean_dlc_output[clean_trial][:, 9]) / 2))).T\n",
    "        point_center_between_hindpaws = np.vstack(([center_between_hindpaws[:, 0] - clean_dlc_output[clean_trial][:, 10], center_between_hindpaws[:, 1] - clean_dlc_output[clean_trial][:, 11]])).T\n",
    "        \n",
    "        point_snout = np.vstack(([clean_dlc_output[clean_trial][:, 0] - clean_dlc_output[clean_trial][:, 10], clean_dlc_output[clean_trial][:, 1] - clean_dlc_output[clean_trial][:, 11]])).T\n",
    "\n",
    "        norm_forepaw_distance = np.zeros(number_trials)\n",
    "        norm_point_center_between_forepaws = np.zeros(number_trials)\n",
    "        norm_point_center_between_hindpaws = np.zeros(number_trials)\n",
    "        norm_point_snout = np.zeros(number_trials)\n",
    "        \n",
    "        for trial in range(1, number_trials):\n",
    "            # Distance is calculated by taking the norm (finding the magnitude) of the difference between the two forepaws' (x,y) values\n",
    "            norm_forepaw_distance[trial] = np.array(np.linalg.norm(clean_dlc_output[clean_trial][trial, 2:4] - clean_dlc_output[clean_trial][trial, 4:6]))\n",
    "            norm_point_center_between_forepaws[trial] = np.linalg.norm(point_center_between_forepaws[trial, :])\n",
    "            norm_point_center_between_hindpaws[trial] = np.linalg.norm(point_center_between_hindpaws[trial, :])\n",
    "            norm_point_snout[trial] = np.linalg.norm(point_snout[trial, :])\n",
    "        \n",
    "        ### At this point, the 4 distance metrics have been calculated \n",
    "        \n",
    "        # smooth_norm_forepaw_distance = np.zeros(number_trials)\n",
    "        # sn_cfp_norm_smth = np.zeros(number_trials)\n",
    "        # sn_chp_norm_smth = np.zeros(number_trials)\n",
    "        # sn_pt_norm_smth = np.zeros(number_trials)\n",
    "        \n",
    "        smooth_norm_forepaw_distance = boxcar_center(norm_forepaw_distance, win_len)\n",
    "        \n",
    "        smooth_norm_distance_snout_center_forepaws = boxcar_center(norm_point_snout - norm_point_center_between_forepaws, win_len)\n",
    "        smooth_norm_distance_snout_center_hindpaws = boxcar_center(norm_point_snout - norm_point_center_between_hindpaws, win_len)\n",
    "        smooth_norm_point_snout = boxcar_center(norm_point_snout, win_len)\n",
    "        \n",
    "        angle_point_snout = np.zeros(number_trials - 1)\n",
    "        displacement_snout = np.zeros(number_trials - 1)\n",
    "        smooth_angle_point_snout = np.zeros(number_trials - 1)\n",
    "        smooth_displacement_snout = np.zeros(number_trials - 1)\n",
    "        \n",
    "        for trial in range(0, number_trials - 1):\n",
    "            next_point_snout_3d = np.hstack([point_snout[trial + 1, :], 0])\n",
    "            this_point_snout_3d = np.hstack([point_snout[trial, :], 0])\n",
    "            cross_product_points = np.cross(next_point_snout_3d, this_point_snout_3d)\n",
    "            angle_point_snout[trial] = np.dot(np.dot(np.sign(cross_product_points[2]), 180) / np.pi,\n",
    "                                  math.atan2(np.linalg.norm(cross_product_points), np.dot(point_snout[trial, :], point_snout[trial + 1, :])))\n",
    "            displacement_snout[trial] = np.linalg.norm(clean_dlc_output[clean_trial][trial + 1, 0:2] - clean_dlc_output[clean_trial][trial, 0:2])\n",
    "        \n",
    "        smooth_angle_point_snout = boxcar_center(angle_point_snout, win_len)\n",
    "        smooth_displacement_snout = boxcar_center(displacement_snout, win_len)\n",
    "        \n",
    "        feats.append(np.vstack((smooth_norm_distance_snout_center_forepaws[1:], smooth_norm_distance_snout_center_hindpaws[1:], smooth_norm_forepaw_distance[1:],\n",
    "                                smooth_norm_point_snout[1:], smooth_angle_point_snout[:], smooth_displacement_snout[:])))\n",
    "    \n",
    "    print(\"--- Feature extraction took %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    # Feature compilation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if comp == 0:\n",
    "        f_10fps = list()\n",
    "        tsne_feats = list()\n",
    "        labels = list()\n",
    "        \n",
    "    for feature_num in range(0, len(feats)):\n",
    "        \n",
    "        feats1 = np.zeros(len(clean_dlc_output[feature_num]))\n",
    "        \n",
    "        for window_index in range(round(fps / 10) - 1, len(feats[feature_num][0]), round(fps / 10)):\n",
    "            \n",
    "            if window_index > round(fps / 10) - 1:\n",
    "                \n",
    "                feats1 = np.concatenate((feats1.reshape(feats1.shape[0], feats1.shape[1]),\n",
    "                                         np.hstack((np.mean((feats[feature_num][0:4, range(window_index - round(fps / 10), window_index)]), axis=1),\n",
    "                                                    np.sum((feats[feature_num][4:7, range(window_index - round(fps / 10), window_index)]),\n",
    "                                                           axis=1))).reshape(len(feats[0]), 1)), axis=1)\n",
    "            else:\n",
    "                feats1 = np.hstack((np.mean((feats[feature_num][0:4, range(window_index - round(fps / 10), window_index)]), axis=1),\n",
    "                                    np.sum((feats[feature_num][4:7, range(window_index - round(fps / 10), window_index)]), axis=1))).reshape(\n",
    "                    len(feats[0]), 1)\n",
    "        \n",
    "        print(\"--- Feature compilation took %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        if comp == 1:\n",
    "            if feature_num > 0:\n",
    "                f_10fps = np.concatenate((f_10fps, feats1), axis=1)\n",
    "            else:\n",
    "                f_10fps = feats1\n",
    "        else:\n",
    "            f_10fps.append(feats1)\n",
    "            if len(f_10fps[feature_num]) < 15000:\n",
    "                p = 50\n",
    "                exag = 12\n",
    "                lr = 200\n",
    "            else:\n",
    "                p = round(f_10fps[feature_num].shape[1] / 300)\n",
    "                exag = round(f_10fps[feature_num].shape[1] / 1200)\n",
    "                lr = round(np.log(f_10fps[feature_num].shape[1]) / 0.04)\n",
    "            start_time = time.time()\n",
    "            ## Run t-SNE dimensionality reduction\n",
    "            np.random.seed(0)  # For reproducibility\n",
    "            print(\n",
    "                'Running the compiled data through t-SNE collapsing the 7 features onto 3 action space coordinates... \\n')\n",
    "            tsne_feats_i = TSNE(n_components=3, perplexity=p, early_exaggeration=exag, learning_rate=lr,\n",
    "                                n_jobs=8).fit_transform(f_10fps[feature_num].T)\n",
    "            tsne_feats.append(tsne_feats_i)\n",
    "            print(\"--- TSNE embedding took %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "            ## Run a Gaussian Mixture Model Expectation Maximization to group the t-SNE clusters\n",
    "            start_time = time.time()\n",
    "            gmm = mixture.GaussianMixture(n_components=kclass, covariance_type='full', tol=0.001, reg_covar=1e-06,\n",
    "                                          max_iter=100, n_init=it, init_params='random').fit(tsne_feats_i)\n",
    "            grp = gmm.predict(tsne_feats_i)\n",
    "            labels.append(grp)\n",
    "            print(\"--- Gaussian mixtures took %s seconds ---\" % (time.time() - start_time))\n",
    "            print(\" Plotting t-SNE with GMM assignments... \")\n",
    "            uk = list(np.unique(labels))\n",
    "            uniqueLabels = []\n",
    "            for i in labels:\n",
    "                indexVal = uk.index(i)\n",
    "                uniqueLabels.append(indexVal)\n",
    "            R = np.linspace(0, 1, len(uk))\n",
    "            color = plt.cm.hsv(R)\n",
    "            fig = go.Figure(\n",
    "                data=[go.Scatter3d(x=tsne_feats_i[:, 0], y=tsne_feats_i[:, 1], z=tsne_feats_i[:, 2], mode='markers',\n",
    "                                   marker=dict(size=2.5, color=color[uniqueLabels], opacity=0.8))])\n",
    "            fig.show()\n",
    "            print('TADA! \\n')\n",
    "    if comp == 1:\n",
    "        if len(f_10fps) < 15000:\n",
    "            p = 50\n",
    "            exag = 12\n",
    "            lr = 200\n",
    "        else:\n",
    "            p = round(f_10fps.shape[1] / 300)\n",
    "            exag = round(f_10fps.shape[1] / 1200)\n",
    "            lr = round(np.log(f_10fps.shape[1]) / 0.04)\n",
    "        start_time = time.time()\n",
    "        ## Run t-SNE dimensionality reduction\n",
    "        np.random.seed(0)  # For reproducibility\n",
    "        print('Running the compiled data through t-SNE collapsing the 7 features onto 3 action space coordinates... \\n')\n",
    "        tsne_feats = TSNE(n_components=3, perplexity=p, early_exaggeration=exag, learning_rate=lr,\n",
    "                          n_jobs=8).fit_transform(f_10fps.T)\n",
    "        print(\"--- TSNE embedding took %s seconds ---\" % (time.time() - start_time))\n",
    "        ## Run a Gaussian Mixture Model Expectation Maximization to group the t-SNE clusters\n",
    "        start_time = time.time()\n",
    "        gmm = mixture.GaussianMixture(n_components=kclass, covariance_type='full', tol=0.001, reg_covar=1e-06,\n",
    "                                      max_iter=100, n_init=it, init_params='random').fit(tsne_feats)\n",
    "        labels = gmm.predict(tsne_feats)\n",
    "        print(\"--- Gaussian mixtures took %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\" Plotting t-SNE with GMM assignments... \")\n",
    "        uk = list(np.unique(labels))\n",
    "        uniqueLabels = []\n",
    "        for i in labels:\n",
    "            indexVal = uk.index(i)\n",
    "            uniqueLabels.append(indexVal)\n",
    "        R = np.linspace(0, 1, len(uk))\n",
    "        color = plt.cm.hsv(R)\n",
    "        fig = go.Figure(data=[go.Scatter3d(x=tsne_feats[:, 0], y=tsne_feats[:, 1], z=tsne_feats[:, 2], mode='markers',\n",
    "                                           marker=dict(size=2.5, color=color[uniqueLabels], opacity=0.8))])\n",
    "        fig.show()\n",
    "        print('TADA! \\n')\n",
    "\n",
    "    return f_10fps, tsne_feats, np.array(uniqueLabels), fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title B-SOiD_MDL2\n",
    "def bsoid_mdl2(f_10fps=None,labels=None,hldout=None,cv_it=None,*args,**kwargs):   \n",
    "    \n",
    "    print('Parsing features into train and test sets')\n",
    "    feats_T=f_10fps.T\n",
    "    labels_T=labels.T\n",
    "    np.random.seed(0)\n",
    "    feats_train, feats_test, labels_train, labels_test = train_test_split(feats_T, labels_T, test_size=hldout, \n",
    "                                                                          random_state=0)\n",
    "    start_time = time.time()\n",
    "    print('Training an SVM classifier (kernel trick: Gaussian)... \\n')\n",
    "    clf = svm.SVC(gamma=0.005, C= 10, random_state=0)\n",
    "    clf.fit(feats_train, labels_train)\n",
    "    scores = cross_val_score(clf, feats_test, labels_test, cv=cv_it)\n",
    "    print(\"--- Training classifier and performing cross-validation {} times took %s seconds ---\".format(cv_it) % (time.time() - start_time))\n",
    "    fig = plt.figure(num=None, figsize=(1.5, 2), dpi=300, facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(\"Performance on {} % Data\".format(hldout*100), fontsize=8, fontweight='bold')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.boxplot(scores, notch=None)\n",
    "    ax.set_xlabel('SVM',fontsize=8)\n",
    "    ax.set_ylabel('Accuracy',fontsize=8)\n",
    "    \n",
    "    return clf,fig,scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pose estimate data (.csv) generated from [DeepLabCut](https://github.com/AlexEMG/DeepLabCut)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#dir_mainAnimal = input('Provide the directory containing all animals and DeepLabCut data: ')\n",
    "dir_mainAnimal = '/Volumes/SharedX/Neuro-Leventhal/analysis/mouseSkilledReaching/DLC_outDir/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load my data\n",
    "all_files = [file for file in os.listdir(dir_mainAnimal) if file.endswith('.csv')]\n",
    "\n",
    "# # ORIGINAL CONTENT FROM BSOID MASTER\n",
    "# # Load your data\n",
    "# # Step 1: change path to \"/content/drive/My Drive/DeepLabCut/\"\n",
    "# # Step 2: change datelist to [\"experiment1\",\"experiment2\",\"more\"]\n",
    "# path = \"/content/drive/My Drive/Colab Notebooks/\"\n",
    "# datelist = [\"041919\",\"042219\"] # get the folder name\n",
    "# all_files = list()\n",
    "# print('Compiling all files...')\n",
    "# for dates in datelist:\n",
    "#     for file in glob.glob(path + dates + \"/*.csv\"):\n",
    "#         all_files.append(file)\n",
    "\n",
    "li = []\n",
    "li_filt = []\n",
    "perc_rect_li = []\n",
    "investigateFiles = []\n",
    "print('High-pass filter for low-likelihood pose estimation:')\n",
    "for filename in all_files:\n",
    "    currDf = pd.read_csv(os.path.join(dir_mainAnimal,filename),low_memory=False)\n",
    "    try:\n",
    "        currDf_filt,perc_rect = adp_filt(currDf)\n",
    "        li.append(currDf)\n",
    "        perc_rect_li.append(perc_rect)\n",
    "        li_filt.append(currDf_filt)\n",
    "    except IndexError:\n",
    "        investigateFiles.append(filename)\n",
    "        continue\n",
    "        \n",
    "data = np.array(li_filt)\n",
    "print('You have compiled .csv files into a',data.shape,'data list.')\n",
    "data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction, dimensionality reduction (t-SNE), and pattern recognition (EM-GMM). **Change fps = camera frame-rate.**![Schematic](https://drive.google.com/uc?id=1_74Bdw8NThaMPj5r66uRMxMKpHz3aP2A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# change fps = camera frame-rate\n",
    "f_10fps,tsne_feats,labels,tsne_fig = bsoid_assign(data,fps = 100,comp = 1,kclass = 50,it = 30) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a multiclass support vector machine (One vs. rest, kernel = Gaussian) classifier using pose as input, and clustered group as label. **Change hldout if you desire a different train/test ratio; change cv_it < 30 if you have a small dataset.**![Schematic](https://drive.google.com/uc?id=1AWcy4BOJ-h3obBEgEGjXyCkhI105MdTJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# change hldout if you desire a different train/test ratio; change cv_it < 30 if you have a small dataset\n",
    "clf,acc_fig,scores = bsoid_mdl2(f_10fps=f_10fps,labels=labels,hldout=0.2,cv_it=30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(np.unique(labels),np.mean(scores))\n",
    "# print(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot multi-feature distributions (histograms by group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(num=None, figsize=(2, 3), dpi=300, facecolor='w', edgecolor='k')\n",
    "R = np.linspace(0,1,len(np.unique(labels)))\n",
    "color=plt.cm.hsv(R)\n",
    "feat_ls = (\"Distance between snout & center forepaw\",\"Distance between snout & center hind paw\",\"forepaw distance\",\n",
    "              \"Body length\",\"Angle\",\"Snout speed\",\"Proximal tail speed\")\n",
    "for j in range(0,f_10fps.shape[0]):\n",
    "  fig = plt.figure(num=None, figsize=(2, 3), dpi=300, facecolor='w', edgecolor='k')\n",
    "  for i in range(0,len(np.unique(labels))):\n",
    "    plt.subplot(len(np.unique(labels)), 1, i+1)\n",
    "    if j == 2 or j == 3 or j == 5 or j == 6:\n",
    "      plt.hist(f_10fps[j,labels == i],\n",
    "              bins = np.linspace(0,np.mean(f_10fps[j,:])+3*np.std(f_10fps[j,:])),\n",
    "              range = (0,np.mean(f_10fps[j,:])+3*np.std(f_10fps[j,:])),\n",
    "              color = color[i], density=True)\n",
    "      plt.xticks(fontsize=6)\n",
    "      plt.yticks(fontsize=6)\n",
    "      fig.suptitle(\"{} pixels\".format(feat_ls[j]), fontsize=8, fontweight='bold')\n",
    "      plt.xlim(0,np.mean(f_10fps[j,:])+3*np.std(f_10fps[j,:]))\n",
    "      if i < len(np.unique(labels))-1:\n",
    "        plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    else:\n",
    "      plt.hist(f_10fps[j,labels == i],\n",
    "              bins = np.linspace(np.mean(f_10fps[j,:])-3*np.std(f_10fps[j,:]),np.mean(f_10fps[j,:])+3*np.std(f_10fps[j,:])),\n",
    "              range = (np.mean(f_10fps[j,:])-3*np.std(f_10fps[j,:]),np.mean(f_10fps[j,:])+3*np.std(f_10fps[j,:])),\n",
    "              color = color[i], density=True)\n",
    "      plt.xticks(fontsize=6)\n",
    "      plt.yticks(fontsize=6)\n",
    "      plt.xlim(np.mean(f_10fps[j,:])-3*np.std(f_10fps[j,:]),np.mean(f_10fps[j,:])+3*np.std(f_10fps[j,:]))\n",
    "      fig.suptitle(\"{} pixels\".format(feat_ls[j]), fontsize=8, fontweight='bold')\n",
    "      if i < len(np.unique(labels))-1:\n",
    "        plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
